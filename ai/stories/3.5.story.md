
# Story 3.5: Implement OCR Text Extraction on iOS (Vision Framework)

**Status:** Draft

## Goal & Context

**User Story:** As a Developer, I need to integrate the Vision Framework (via `VisionOcrProvider.swift`) within the iOS Share Extension to perform OCR on a received image, so that text can be extracted from Reddit comments.

**Context:** This story is the iOS counterpart to Story 3.2 (ML Kit on Android). It implements the OCR logic using Apple's Vision Framework. It takes the `UIImage` received by the Share Extension (Story 3.4) and extracts text from it. This text will then be displayed or further processed.

## Detailed Requirements

- Use Apple's Vision Framework (`VNRecognizeTextRequest`) for on-device text recognition.
- Create a service/provider class (e.g., `VisionOcrProvider`) in `iosApp` that accepts a `UIImage` and returns the recognized text as a string (or a structured result).
- Prioritize accuracy in the `VNRecognizeTextRequest`.
- Handle potential Vision framework initialization and processing errors.
- Focus on extracting English text. The result will be sent to the KMP `shared` module.

## Acceptance Criteria (ACs)

- AC1: The `VisionOcrProvider` successfully processes a sample screenshot of a Reddit comment and extracts text within the Share Extension.
- AC2: The extracted text is returned as a string.
- AC3: Errors during OCR processing (e.g., no text found, low confidence) are handled gracefully and can be reported (e.g., return nil, empty string, or an error state).
- AC4: OCR is performed on-device.

## Technical Implementation Context

**Guidance:** Use the following details for implementation. Refer to the linked `docs/` files for broader context if needed.

- **Relevant Files:**

    - Files to Create:
        - `iosApp/iosApp/ocr/VisionOcrProvider.swift` (This provider might be in the main app target to be shared with the extension, or directly in the extension if not reused elsewhere. `project-structure.md` places it in `iosApp/iosApp/ocr/` implying main app target, which is good for potential reuse).
    - Files to Modify:
        - `iosApp/SubLingoShareExtension/ShareViewController.swift` (To call `VisionOcrProvider`).
    - *(Hint: See `docs/project-structure.md` for file locations.)*

- **Key Technologies:**

    - Swift, iOS SDK
    - Vision Framework (`VNRecognizeTextRequest`, `VNImageRequestHandler`)
    - `CGImage` (Vision usually works with `CGImage`)
    - *(Hint: See `docs/tech-stack.md`)*

- **API Interactions / SDK Usage:**

    - `VNRecognizeTextRequest { request, error in ... }`
    - Setting `recognitionLevel` to `.accurate` on `VNRecognizeTextRequest`.
    - Setting `recognitionLanguages` to `["en-US"]`.
    - `VNImageRequestHandler(cgImage: cgImage, options: [:])`.
    - `handler.perform([request])`.
    - Accessing results: `request.results as? [VNRecognizedTextObservation]`.
    - Extracting text from observations: `observation.topCandidates(1).first?.string`.

- **Data Structures:**

    - Input: `UIImage` (needs conversion to `CGImage`)
    - Output: `String` (extracted text)

- **Environment Variables:**

    - Not applicable.

- **Coding Standards Notes:**

    - `VisionOcrProvider` should encapsulate Vision Framework logic.
    - OCR processing should be asynchronous. The Vision request handler itself is synchronous, so dispatch it to a background queue if called from the main thread. Return results via completion handler or `async/await`.
    - Error handling for Vision requests is important.
    - *(Hint: See `docs/coding-standards.md`)*

## Tasks / Subtasks

- [ ] Task 1: Create `VisionOcrProvider.swift`.
    - [ ] Subtask 1.1: Define a class `VisionOcrProvider`.
    - [ ] Subtask 1.2: Implement a public function `recognizeText(from image: UIImage, completion: @escaping (String?) -> Void)` or an `async throws -> String?` function.
    - [ ] Subtask 1.3: Inside the function, convert `UIImage` to `CGImage`. If `cgImage` is nil, call completion with `nil` or throw error.
    - [ ] Subtask 1.4: Create a `VNRecognizeTextRequest`.
        - Set `recognitionLevel = .accurate`.
        - Set `recognitionLanguages = ["en-US"]`.
        - In its completion handler, process `VNRecognizedTextObservation` results to build a single string. Call the main completion handler with the assembled string or `nil`.
    - [ ] Subtask 1.5: Create a `VNImageRequestHandler` with the `cgImage`.
    - [ ] Subtask 1.6: Perform the request: `try? handler.perform([textRequest])`. Dispatch this to a background queue if necessary.
- [ ] Task 2: In `ShareViewController.swift`, after obtaining the `UIImage` (from Story 3.4):
    - [ ] Subtask 2.1: Create an instance of `VisionOcrProvider`.
    - [ ] Subtask 2.2: Call `visionOcrProvider.recognizeText(from: uiImage) { extractedText in ... }`.
- [ ] Task 3: Test with a sample Reddit comment screenshot (AC1).
    - [ ] Subtask 3.1: Manually provide a test `UIImage` to `VisionOcrProvider`.
    - [ ] Subtask 3.2: Log or debug the extracted text from the completion handler.
- [ ] Task 4: Verify extracted text is a string (AC2).
- [ ] Task 5: Test error handling (e.g., process an image with no text) (AC3).
- [ ] Task 6: Confirm Vision Framework performs on-device OCR (AC4 - this is its default behavior).

## Testing Requirements

**Guidance:** Verify implementation against the ACs using the following tests.

- **Unit Tests:**
    - Can test parts of `VisionOcrProvider` if logic for text assembly from observations is complex. Mocking Vision results is hard.
- **Integration Tests:** Not for MVP.
- **Manual/CLI Verification:**
    - AC1: Provide a clear screenshot of a Reddit comment to the provider via the Share Extension. Log the output. Compare with actual text.
    - AC2: Check the type and content of the returned string.
    - AC3: Provide a blank image. Check for graceful handling (e.g., `nil` or empty string returned, no crash).
    - AC4: Assumed by using Vision Framework.
- *(Hint: See `docs/testing-strategy.md`. Specialized OCR accuracy testing is in Story 6.6.)*

## Story Wrap Up (Agent Populates After Execution)

- **Agent Model Used:** `<Agent Model Name/Version>`
- **Completion Notes:** {}
- **Change Log:**
    - Initial Draft
