
# Story 3.7: Basic Image Preprocessing for OCR Improvement (Platform Specific)

**Status:** Draft

## Goal & Context

**User Story:** As a Developer, I want to implement basic image preprocessing routines (e.g., grayscale conversion) in the platform-specific OCR providers (`MlKitOcrProvider`, `VisionOcrProvider`) before sending an image to OCR, so that OCR accuracy can be potentially improved on varied Reddit comment styles.

**Context:** This story aims to enhance OCR accuracy by adding simple image preprocessing steps. Reddit comments can appear in light/dark themes, with various colors. Converting images to grayscale might provide a more consistent input for ML Kit and Vision Framework, potentially improving their text recognition. This is an iterative improvement.

## Detailed Requirements

- **Android (`MlKitOcrProvider`):** Implement a function to convert the input `Bitmap` to grayscale before passing it to ML Kit.
- **iOS (`VisionOcrProvider`):** Implement a function to convert the input `UIImage` to grayscale (e.g., using Core Image filters) before passing it to the Vision Framework.
- Other basic preprocessing like adjusting contrast or binarization could be considered if straightforward and demonstrably beneficial, but grayscale is the minimum.
- The goal is to standardize the image somewhat to aid the OCR engines.

## Acceptance Criteria (ACs)

- AC1: Images are converted to grayscale within `MlKitOcrProvider` (Android) and `VisionOcrProvider` (iOS) before being sent to the respective OCR engines.
- AC2: The preprocessing step does not significantly degrade overall OCR processing time (i.e., keeps it within NFRs).
- AC3: Qualitative testing on a few sample Reddit comment screenshots shows that grayscale conversion does not harm (and ideally helps or has no negative effect on) OCR results compared to no preprocessing.

## Technical Implementation Context

**Guidance:** Use the following details for implementation. Refer to the linked `docs/` files for broader context if needed.

- **Relevant Files:**

    - Files to Modify:
        - `composeApp/src/androidMain/kotlin/com/nguyenmoclam/sublingo/android/ocr/MlKitOcrProvider.kt`
        - `iosApp/iosApp/ocr/VisionOcrProvider.swift`
    - *(Hint: See `docs/project-structure.md`.)*

- **Key Technologies:**

    - Android: `android.graphics.ColorMatrixColorFilter`, `ColorMatrix.setSaturation(0f)`, `Paint`.
    - iOS: Core Image filters (e.g., `CIPhotoEffectNoir` or `CIColorControls` with saturation set to 0).
    - *(Hint: See `docs/tech-stack.md`)*

- **API Interactions / SDK Usage:**

    - Android: Drawing original bitmap to a new bitmap using a `Paint` object with a grayscale `ColorMatrixColorFilter`.
    - iOS: Applying `CIFilter` to a `CIImage` created from `UIImage`, then rendering back to `UIImage` or `CGImage`.

- **Data Structures:**

    - `Bitmap` (Android), `UIImage`/`CGImage` (iOS).

- **Environment Variables:**

    - Not applicable.

- **Coding Standards Notes:**

    - Preprocessing functions should be efficient.
    - The option to toggle preprocessing could be added for testing/debugging if complex.
    - *(Hint: See `docs/coding-standards.md`)*

## Tasks / Subtasks

- [ ] Task 1: Implement grayscale conversion in `MlKitOcrProvider.kt` (Android).
    - [ ] Subtask 1.1: Create a private function `fun Bitmap.toGrayscale(): Bitmap`.
    - [ ] Subtask 1.2: Inside `recognizeText`, call this conversion before `InputImage.fromBitmap()`.
- [ ] Task 2: Implement grayscale conversion in `VisionOcrProvider.swift` (iOS).
    - [ ] Subtask 2.1: Create a private function `func convertToGrayScale(image: UIImage) -> UIImage?`.
    - [ ] Subtask 2.2: Inside `recognizeText`, call this conversion before creating `CGImage` for `VNImageRequestHandler`.
- [ ] Task 3: Test grayscale conversion visually (save preprocessed image temporarily) (AC1).
- [ ] Task 4: Measure OCR time with and without preprocessing on a few samples to check performance impact (AC2).
- [ ] Task 5: Qualitatively compare OCR results on 3-5 diverse Reddit screenshots (light/dark mode, different colors) with and without grayscale to assess impact (AC3). Document findings.

## Testing Requirements

**Guidance:** Verify implementation against the ACs using the following tests.

- **Unit Tests:**
    - Could unit test the grayscale conversion functions themselves if they are pure image manipulation logic.
- **Integration Tests:** Not for MVP.
- **Manual/CLI Verification:**
    - AC1: Debug and visually inspect the image being sent to OCR engines to confirm it's grayscale.
    - AC2: Time the OCR process with and without this step on a few sample images.
    - AC3: Perform side-by-side OCR accuracy comparisons on a small set of diverse images. More extensive testing in Story 6.6.
- *(Hint: See `docs/testing-strategy.md`. Story 6.6 will perform more focused OCR accuracy testing.)*

## Story Wrap Up (Agent Populates After Execution)

- **Agent Model Used:** `<Agent Model Name/Version>`
- **Completion Notes:** {Include findings from qualitative testing AC3}
- **Change Log:**
    - Initial Draft

