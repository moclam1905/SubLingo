
# Story 6.5: Performance Review and Bottleneck Identification

**Status:** Draft

## Goal & Context

**User Story:** As a Developer, I want to review the performance of critical operations (offline lookup, OCR, online translation) against NFRs and identify any major bottlenecks for potential optimization.

**Context:** This story ensures the app meets the non-functional performance requirements defined in the PRD. It involves measuring the speed of key operations and identifying any areas that are unacceptably slow. While major optimization might be post-MVP, identifying bottlenecks is crucial.

## Detailed Requirements

- Re-measure performance for:
    - Offline word lookup speed (Target: < 2 seconds overall, KMP Service from Story 2.2 target: < 500ms). Test via KMP `OfflineDictionaryService`.
    - OCR processing speed (Target: < 3s). Test on-device `MlKitOcrProvider` (Android) and `VisionOcrProvider` (iOS) with sample images.
    - Online sentence translation API call (Target API: ≤ 2s, user-perceived will be higher). Test KMP `OnlineTranslationService` response time, factoring in network from target region.
- Perform these tests on target devices/emulators.
- Identify any operations consistently failing to meet NFRs or exhibiting significant lag.
- Document identified bottlenecks. This story is about identification; actual optimization might be a separate task or deferred if minor and MVP goals are met.

## Acceptance Criteria (ACs)

- AC1: Performance metrics for key operations (offline lookup, OCR, online translation) are measured and documented against NFRs from `prd.md`.
- AC2: Any operations significantly missing performance targets are identified.
- AC3: A list of potential performance bottlenecks is created (if any).

## Technical Implementation Context

**Guidance:** Use the following details for implementation. Refer to the linked `docs/` files for broader context if needed.

- **Relevant Files:**
    - No specific code creation, but involves interacting with:
        - `OfflineDictionaryService` / `OfflineDictionaryRepositoryImpl` (KMP)
        - `MlKitOcrProvider` (Android)
        - `VisionOcrProvider` (iOS)
        - `OnlineTranslationService` / `OnlineTranslationRepositoryImpl` (KMP)
    - A new document might be created to log performance results, e.g., `docs/performance_review_mvp.md`.
    - _(Hint: Review NFRs in `prd.md`.)_

- **Key Technologies:**
    - Android Studio Profiler (CPU, Memory, Network).
    - Xcode Instruments (Time Profiler, Network, etc.).
    - Simple logging with timestamps for KMP service calls.
    - _(Hint: See `docs/tech-stack.md`)_

- **API Interactions / SDK Usage:**
    - Invoking the app's own services for testing.

- **Data Structures:**
    - Not applicable.

- **Environment Variables:**
    - Not applicable.

- **Coding Standards Notes:**
    - Perform tests on representative devices/emulators, not just high-end developer machines.
    - Test under realistic conditions (e.g., average network for online tests).
    - Be methodical in measurements: repeat tests multiple times and average results.
    - _(Hint: See `docs/coding-standards.md`)_

## Tasks / Subtasks

- [ ] Task 1: Set up a consistent testing environment (specific devices/emulators, sample data for lookups/OCR/translation).
- [ ] Task 2: Measure offline word lookup speed.
    - Call `OfflineDictionaryService.findWord()` (or equivalent use case) multiple times for different words.
    - Log start/end times within the KMP service call. Exclude initial DB load if possible.
    - Document results against NFR (< 500ms for service, < 2s user perceived). (AC1 part 1)
- [ ] Task 3: Measure OCR processing speed.
    - Android: Time `MlKitOcrProvider.recognizeText()` with sample comment images.
    - iOS: Time `VisionOcrProvider.recognizeText()` with sample comment images.
    - Document results against NFR (< 3s). (AC1 part 2)
- [ ] Task 4: Measure online sentence translation API call duration.
    - Time the KMP `OnlineTranslationService`'s call to the external API (excluding UI overhead, focus on Ktor client call to response received).
    - Test from a network representative of target users if possible (e.g., Vietnam).
    - Document results against NFR (API call ≤ 2s). (AC1 part 3)
- [ ] Task 5: Compare all measured metrics against PRD NFRs.
- [ ] Task 6: Identify any operations consistently failing NFRs or showing significant lag (AC2).
- [ ] Task 7: For identified issues, try to pinpoint the bottleneck (e.g., slow DB query, inefficient image processing, slow network parsing, Ktor client config). Use profilers if needed. (AC3)
- [ ] Task 8: Document all findings, measurements, and identified bottlenecks in `docs/performance_review_mvp.md` (or similar).

## Testing Requirements

**Guidance:** Verify implementation against the ACs using the following tests.
- **Unit Tests:** Not applicable for performance measurement itself.
- **Integration Tests:** Not for MVP.
- **Manual/CLI Verification:**
    - AC1 is met by executing the measurement tasks and documenting them.
    - AC2 is met if the documentation clearly lists operations failing NFRs.
    - AC3 is met if the documentation includes a list of suspected bottlenecks for the failing operations.
- _(Hint: See `docs/testing-strategy.md` which mentions confirming NFRs.)_

## Story Wrap Up (Agent Populates After Execution)

- **Agent Model Used:** `<Agent Model Name/Version>`
- **Completion Notes:** {Summary of performance findings and identified bottlenecks, link to results document}
- **Change Log:**
    - Initial Draft