
# Story 6.6: Focused OCR Accuracy Testing and Minor Adjustments

**Status:** Draft

## Goal & Context

**User Story:** As a QA/Developer, I want to test OCR accuracy on a diverse set of Reddit comment screenshots and make minor adjustments to preprocessing (Story 3.7) or cropping (Tech Story A.2) if clear benefits are identified, to maximize OCR reliability for MVP.

**Context:** This story specifically addresses the NFR related to OCR accuracy. It involves more rigorous testing than the initial implementation stories (3.2, 3.5). It builds upon the basic preprocessing from Story 3.7 and potentially the robust cropping from Tech Story A.2 (if implemented). The goal is to understand current OCR quality and make small, low-effort tweaks if they offer significant improvement.

## Detailed Requirements

- Collect a diverse set of at least 20-30 Reddit comment screenshots:
    - Different themes (light/dark).
    - Various system font sizes.
    - Different comment densities and layouts (e.g., nested comments, comments with icons/flairs).
- Test OCR accuracy (ML Kit on Android, Vision Framework on iOS) on these samples with current preprocessing.
- If specific patterns of failure are noted, investigate if minor, low-effort adjustments to image preprocessing (e.g., slight contrast change, grayscale toggle, small refinement to cropping logic) can yield noticeable improvements without adding significant complexity.
- Document OCR performance on the test set (e.g., success rate, common error types).

## Acceptance Criteria (ACs)

- AC1: OCR accuracy is tested against a documented set of diverse Reddit comment screenshots (at least 20-30).
- AC2: Results (successful extractions, common failure types) are documented.
- AC3: At least one minor preprocessing/cropping adjustment is attempted and its impact evaluated if initial results show consistent, easily addressable issues.
- AC4: Overall OCR success rate and limitations for MVP are better understood and documented.

## Technical Implementation Context

**Guidance:** Use the following details for implementation. Refer to the linked `docs/` files for broader context if needed.

- **Relevant Files:**
    - Files to potentially Modify (if adjustments are made):
        - `composeApp/src/androidMain/kotlin/com/nguyenmoclam/sublingo/android/ocr/MlKitOcrProvider.kt` (preprocessing logic)
        - `composeApp/src/androidMain/kotlin/com/nguyenmoclam/sublingo/android/service/FloatingBubbleService.kt` (cropping logic - Tech Story A.2)
        - `iosApp/iosApp/ocr/VisionOcrProvider.swift` (preprocessing logic)
    - A new document for OCR test results, e.g., `docs/ocr_accuracy_test_results_mvp.md`.
    - _(Hint: See `docs/testing-strategy.md` section 2.4 OCR Accuracy Testing.)_

- **Key Technologies:**
    - ML Kit Text Recognition (Android)
    - Vision Framework (iOS)
    - Image manipulation libraries/APIs (if making adjustments to preprocessing).
    - _(Hint: See `docs/tech-stack.md`)_

- **API Interactions / SDK Usage:**
    - Using the implemented OCR providers.

- **Data Structures:**
    - Not applicable beyond test images and result logs.

- **Environment Variables:**
    - Not applicable.

- **Coding Standards Notes:**
    - Test set should be truly diverse.
    - "Minor, low-effort adjustments" means avoiding significant refactoring or new complex algorithms for this story.
    - Documenting failures is as important as successes.
    - _(Hint: See `docs/coding-standards.md`)_

## Tasks / Subtasks

- [ ] Task 1: Assemble the diverse set of 20-30+ Reddit comment screenshots. Store them in a structured way for testing.
- [ ] Task 2: Create a test plan/spreadsheet to track each test image, the expected text, actual OCR output (Android & iOS), and any errors.
- [ ] Task 3: Perform OCR on all test images using the current Android implementation. Record results. (AC1 Android part)
- [ ] Task 4: Perform OCR on all test images using the current iOS implementation. Record results. (AC1 iOS part)
- [ ] Task 5: Analyze results: Identify common failure patterns (e.g., issues with dark mode, specific fonts, nested comment indentation, icons/flairs interfering). (AC2)
- [ ] Task 6: Based on analysis, identify 1-2 potential minor preprocessing/cropping adjustments (e.g., if grayscale from Story 3.7 wasn't universally applied, test its impact; try a slight change in contrast if images are consistently too washed out/dark; adjust cropping box size/heuristics from Tech Story A.2 if consistently missing relevant text). (AC3 part 1)
- [ ] Task 7: Implement the chosen minor adjustment(s).
- [ ] Task 8: Re-test the problematic subset of images (or the full set if adjustment is general) with the adjustments. Evaluate impact (compare new results to previous). (AC3 part 2)
- [ ] Task 9: Document final OCR success rates (e.g., % of images with fully correct text, partially correct), common remaining limitations, and findings from adjustments in `docs/ocr_accuracy_test_results_mvp.md`. (AC4)

## Testing Requirements

**Guidance:** Verify implementation against the ACs using the following tests.
- **Unit Tests:** Not directly applicable to the testing process itself.
- **Integration Tests:** Not for MVP.
- **Manual/CLI Verification:**
    - AC1: The execution of the test plan on the diverse image set. The documentation of this test set.
    - AC2: The spreadsheet/document containing actual vs. expected results and failure analysis.
    - AC3: If an adjustment was made, evidence of its implementation and the re-evaluation of its impact (e.g., updated results for some images).
    - AC4: The final report document detailing overall OCR performance and known limitations.
- _(Hint: This story is primarily a structured testing and minor iteration task. See `docs/testing-strategy.md` section 2.4.)_

## Story Wrap Up (Agent Populates After Execution)

- **Agent Model Used:** `<Agent Model Name/Version>`
- **Completion Notes:** {Summary of OCR accuracy findings, any adjustments made, and link to test results document}
- **Change Log:**
    - Initial Draft
